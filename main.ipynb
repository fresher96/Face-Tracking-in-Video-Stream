{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For compatibility with google colab\n",
    "!pip install face_recognition ipdb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'http://192.168.0.103:8080/shot.jpg'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config_file;\n",
    "configs = config_file.readConfigs();\n",
    "configs['camera_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import cv2;\n",
    "import math;\n",
    "from tqdm.notebook import tqdm;\n",
    "from time import sleep;\n",
    "import termcolor;\n",
    "from ipdb import set_trace;\n",
    "import PIL;\n",
    "import IPython;\n",
    "from io import BytesIO;\n",
    "\n",
    "class VideoStreamBase():\n",
    "\n",
    "    def logPeople(self, people):\n",
    "\n",
    "        def isPresent1(id, i):\n",
    "            if(i >= len(people)): return False;\n",
    "            return id in [id_ for _, id_, _ in people[i]];\n",
    "        \n",
    "        def isPresent(id, i, j):\n",
    "            for k in range(i, j + 1):\n",
    "                if(isPresent1(id, k)):\n",
    "                    return True;\n",
    "            return False;\n",
    "        \n",
    "        def getLength():\n",
    "            ret = 0;\n",
    "            for frame in people:\n",
    "                for (_, id, _) in frame:\n",
    "                    if(id is None): continue;\n",
    "                    ret = max(ret, id);\n",
    "            return ret + 1;\n",
    "\n",
    "\n",
    "        t1 = configs['frames_to_enter'];\n",
    "        t2 = configs['frames_to_exit'];\n",
    "\n",
    "        data = pd.DataFrame(columns=['face_id', 'person_id', 'name', 'timestamp_first', 'timestamp_last']);\n",
    "\n",
    "        idx = 0;\n",
    "        entryTime = [None] * getLength();\n",
    "        for i, frame in enumerate(people):\n",
    "            for j, person in enumerate(frame):\n",
    "                id = person[1];\n",
    "\n",
    "                if(id is None):\n",
    "                    continue;\n",
    "\n",
    "                if(entryTime[id] is None and isPresent(id, i + 1, i + t1)):\n",
    "                    entryTime[id] = (i, person);\n",
    "\n",
    "                if(isPresent(id, i + 1, i + t2)):\n",
    "                    continue;\n",
    "\n",
    "                if(entryTime[id] is not None):\n",
    "                    data.at[idx] = list(person) + [entryTime[id][0], i];\n",
    "                    idx += 1;\n",
    "                    entryTime[id] = None;\n",
    "                \n",
    "        for id, el in enumerate(entryTime):\n",
    "            if(el is None): continue;\n",
    "            data.at[idx] = list(el[1]) + [el[0], len(people) - 1];\n",
    "            idx += 1;\n",
    "\n",
    "        data.to_csv(configs['db_presence']);\n",
    "        return data;\n",
    "\n",
    "    def __del__(self):\n",
    "        cv2.VideoCapture(0).release();\n",
    "        cv2.destroyAllWindows();\n",
    "\n",
    "    def getImage(self) -> np.ndarray:\n",
    "        raise NotImplementedError();\n",
    "\n",
    "    def displayVideo(self, limit: int = 0, lag: int = 0, display_id: int = 1, width: int = 400, height: int = 200):\n",
    "        try:\n",
    "            while(self.displayImage(display_id, width, height)):\n",
    "                sleep(lag);\n",
    "        except(KeyboardInterrupt):\n",
    "            print(termcolor.colored('video stream stopped voluntarily', 'green'));\n",
    "\n",
    "    def displayImage(self, display_id: int = None, width: int = 400, height: int = 200, img = None) -> bool:\n",
    "        img = self.getImage() if img is None else img;\n",
    "        if(img is None): return False;\n",
    "\n",
    "        img = PIL.Image.fromarray(img, 'RGB')\n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, format=\"jpeg\")\n",
    "        display(\n",
    "            IPython.display.Image(\n",
    "                data=buffer.getvalue(), format='jpeg', width=width, height=height\n",
    "                ), display_id=display_id);\n",
    "\n",
    "        return True;\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError();\n",
    "\n",
    "    def fps(self):\n",
    "        return 10;\n",
    "\n",
    "    def download(self, path: str = configs['output_file'], fps: float = None, limit: int = None, display: bool = False,\n",
    "                 safeMode: bool = True, width: int = None, height: int = None):\n",
    "\n",
    "        nFrame = limit if limit is not None else (len(self) - (len(self) != 1));\n",
    "        if(nFrame == 0): raise Exception('No Frames Found');\n",
    "\n",
    "        people = [[]];\n",
    "        try:    img = self.getImage(people[-1]);\n",
    "        except: img = self.getImage();\n",
    "\n",
    "        if(height is None): height = img.shape[0];\n",
    "        if(width  is None): width  = img.shape[1];\n",
    "\n",
    "        fourcc =  cv2.VideoWriter_fourcc(*'XVID');\n",
    "        fps_ = self.fps() if fps is None else fps;\n",
    "        outputVideo = cv2.VideoWriter(path, fourcc, fps_, (width, height), 1)\n",
    "\n",
    "\n",
    "\n",
    "        with tqdm(total=nFrame) as progressbar:\n",
    "            currentFrame = 0;\n",
    "            nextImg = None;\n",
    "            while(currentFrame < nFrame and img is not None):\n",
    "                try:\n",
    "                    if(display): self.displayImage(1, width, height, img);\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB);\n",
    "\n",
    "                    people.append([]);\n",
    "                    try:    nextImg = self.getImage(people[-1]);\n",
    "                    except: nextImg = self.getImage();\n",
    "\n",
    "                except Exception as e:\n",
    "                    if(safeMode):\n",
    "                        print(termcolor.colored('Exception:', 'red'));\n",
    "                        print(e);\n",
    "                    else:\n",
    "                        raise e;\n",
    "\n",
    "                outputVideo.write(img);\n",
    "                currentFrame += 1;\n",
    "                progressbar.update(1);\n",
    "                img = nextImg;\n",
    "\n",
    "        outputVideo.release();\n",
    "        return self.logPeople(people);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import face_recognition;\n",
    "import os;\n",
    "import json;\n",
    "\n",
    "\n",
    "class FaceDetector(VideoStreamBase):\n",
    "\n",
    "    video: VideoStreamBase\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video);\n",
    "\n",
    "    def fps(self):\n",
    "        return self.video.fps();\n",
    "\n",
    "    def __init__(self, video: VideoStreamBase):\n",
    "        self.video = video;\n",
    "\n",
    "        self.known_faces = None;\n",
    "        with open(configs['db_face'], 'r') as f:\n",
    "            embeddings = json.load(f);\n",
    "\n",
    "            self.known_faces = [None] * len(embeddings);\n",
    "            for el in embeddings:\n",
    "                self.known_faces[el['id']] = np.array(el['embedding']);\n",
    "\n",
    "        self.known_names = None;\n",
    "        with open(configs['db_person'], 'r') as f:\n",
    "            people = json.load(f);\n",
    "\n",
    "            self.known_names = [None] * len(people);\n",
    "            assert(len(self.known_names) == len(self.known_faces))\n",
    "\n",
    "            for el in people:\n",
    "                self.known_names[el['face']] = (el['id'], el['name']);\n",
    "\n",
    "    def getImage(self, people = []):\n",
    "        img = self.video.getImage();\n",
    "        if(img is None): return None;\n",
    "\n",
    "        face_locations = face_recognition.face_locations(img, model=configs['face_locations_model'])\n",
    "        face_encodings = face_recognition.face_encodings(img, face_locations, model=configs['face_encodings_model'])\n",
    "        # set_trace();\n",
    "\n",
    "\n",
    "        for face_encoding in face_encodings:\n",
    "\n",
    "            # print(type(face_encoding), face_encoding);\n",
    "            # print(type(self.known_faces[0]), self.known_faces[0]);\n",
    "\n",
    "            tolerance = 0.60;\n",
    "            # match = face_recognition.compare_faces(self.known_faces, face_encoding, tolerance=tolerance)\n",
    "            match = face_recognition.face_distance(self.known_faces, face_encoding)\n",
    "\n",
    "            # id = np.argmax(match);\n",
    "            # name = self.known_names[id] if match[id] else None;\n",
    "\n",
    "            id = np.argmin(match);\n",
    "            personId, name = (self.known_names[id]) if (match[id] <= tolerance) else (None, None);\n",
    "\n",
    "            people.append((id, personId, name));\n",
    "            # print(people[-1]);\n",
    "\n",
    "        for (top, right, bottom, left), name in zip(face_locations, people):\n",
    "            name = name[2];\n",
    "\n",
    "            color = (255, 0, 0) if name is None else (0, 255, 0);\n",
    "            cv2.rectangle(img, (left, top), (right, bottom), color, 2);\n",
    "\n",
    "            if(name is None): continue;\n",
    "\n",
    "            cv2.rectangle(img, (left, bottom - 42), (right, bottom), color, cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(img, name, (left + 5, bottom - 8), font, 1.5, (0, 0, 0), 2);\n",
    "\n",
    "        return img;\n",
    "\n",
    "# video = FaceDetector(VideoReader(videoFile), facesDir);\n",
    "# video.download(outputFile, 25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Classes for Local Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import cv2;\n",
    "import termcolor;\n",
    "\n",
    "\n",
    "class LocalVideoStream(VideoStreamBase):\n",
    "\n",
    "    def displayImage(self, display_id: int = None, width: int = 400, height: int = 200, img = None) -> bool:\n",
    "        img = self.getImage() if img is None else img;\n",
    "        if(img is None): return False;\n",
    "\n",
    "        if(cv2.waitKey(1) & 0xFF == ord('q')): # press `q` to break\n",
    "            print(termcolor.colored('video stream stopped voluntarily', 'green'));\n",
    "            print(termcolor.colored('WARNING: object deleted', 'yellow'));\n",
    "    #         self.__del__();\n",
    "            super(LocalVideoStream, self).__del__();\n",
    "\n",
    "            return False;\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR);\n",
    "        cv2.imshow('Streaming...', img);\n",
    "\n",
    "        return True;\n",
    "\n",
    "    def displayVideo_(self):\n",
    "        while(True):\n",
    "            img = self.getImage();\n",
    "\n",
    "            if(img is None): break;\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR);\n",
    "            cv2.imshow('Streaming', img);\n",
    "\n",
    "            if(cv2.waitKey(1) & 0xFF == ord('q')): # press `q` to break\n",
    "                break;\n",
    "\n",
    "        print(termcolor.colored('video stream stopped voluntarily', 'green'));\n",
    "        print(termcolor.colored('WARNING: object deleted', 'yellow'));\n",
    "#         self.__del__();\n",
    "        super(LocalVideoStream, self).__del__();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LocalFaceDetector(LocalVideoStream, FaceDetector):\n",
    "    def __init__(self, video: VideoStreamBase):\n",
    "        super(LocalFaceDetector, self).__init__(video);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Online Setting\n",
    "Uses public url to get frames from the video stream."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import requests;\n",
    "import cv2;\n",
    "from time import sleep;\n",
    "\n",
    "class Camera(VideoStreamBase):\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url;\n",
    "\n",
    "    def getFrame(self):\n",
    "        img_resp = requests.get(self.url);\n",
    "        return img_resp;\n",
    "\n",
    "    def getImage(self):\n",
    "        img = self.getFrame();\n",
    "        img = np.array(bytearray(img.content), dtype=np.uint8);\n",
    "\n",
    "        img = cv2.imdecode(img, cv2.IMREAD_COLOR);\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return img;\n",
    "\n",
    "\n",
    "# camera = Camera(configs['camera_url']);\n",
    "# camera.displayImage();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# video = FaceDetector(Camera(configs['camera_url']));\n",
    "# video.download(configs['output_file'], limit=200, display=True);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# offline Setting\n",
    "Uses a video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import IPython\n",
    "import PIL\n",
    "\n",
    "\n",
    "class VideoReader(LocalVideoStream):\n",
    "\n",
    "    def __init__(self, file):\n",
    "        self.capture = cv2.VideoCapture(file)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.capture.release()\n",
    "        super(VideoReader, self).__del__();\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.capture.get(cv2.CAP_PROP_FRAME_COUNT));\n",
    "\n",
    "    def fps(self):\n",
    "        return self.capture.get(cv2.CAP_PROP_FPS);\n",
    "\n",
    "    def getImage(self):\n",
    "        ret, frame = self.capture.read()\n",
    "        if(ret == False): return None;\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return frame;\n",
    "\n",
    "# video = VideoReader(configs['video_file']);\n",
    "# video.displayVideo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# video = LocalFaceDetector(VideoReader(configs['video_file']));\n",
    "# video.download(configs['output_file']);"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Local Setting\n",
    "Uses a url accessed locally (within the same LAN) to get frames from the video stream."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class LocalCamera(LocalVideoStream, Camera):\n",
    "    def __init__(self, url: str):\n",
    "        super(LocalCamera, self).__init__(url);\n",
    "\n",
    "# video = LocalCamera(cameraUrl);\n",
    "# video.displayVideo();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# video = LocalFaceDetector(LocalCamera(configs['camera_url']));\n",
    "# video.displayVideo();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Laptop Webcam Setting\n",
    "Uses the webcam as the video stream."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import cv2;\n",
    "\n",
    "\n",
    "class WebCam(LocalVideoStream):\n",
    "\n",
    "    def __init__(self, deviceId: int = 0):\n",
    "        self.capture = cv2.VideoCapture(deviceId);\n",
    "\n",
    "    def Test(self):\n",
    "        print('child');\n",
    "\n",
    "#     def __del__(self):\n",
    "#         print('releasing capture');\n",
    "#         self.capture.release();\n",
    "#         super(WebCam, self).__del__();\n",
    "\n",
    "    def getImage(self):\n",
    "        ret, img = self.capture.read();\n",
    "        if(not ret): return None;\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img;\n",
    "\n",
    "# video = WebCam();\n",
    "# video.displayVideo();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# video = LocalFaceDetector(WebCam());\n",
    "# video.download(display=True, limit=1000);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: webcam\n",
      "\u001B[32mvideo stream stopped voluntarily\u001B[0m\n",
      "\u001B[33mWARNING: object deleted\u001B[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=10000000000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "741897339e42478191d20963618b7550"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    configs = config_file.readConfigs();\n",
    "    \n",
    "    mode = configs['mode']\n",
    "    print('mode:', mode);\n",
    "\n",
    "    if(mode == 'online'):\n",
    "        video = FaceDetector(Camera(configs['camera_url']));\n",
    "        video.download(display=True, limit=1e10);\n",
    "    elif(mode == 'local'):\n",
    "        video = LocalFaceDetector(LocalCamera(configs['camera_url']));\n",
    "        video.download(display=True, limit=1e10);\n",
    "    elif(mode == 'webcam'):\n",
    "        video = LocalFaceDetector(WebCam());\n",
    "        video.download(display=True, limit=1e10);\n",
    "    else:\n",
    "        video = LocalFaceDetector(VideoReader(configs['video_file']));\n",
    "        video.download(display=True);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (AIR_project)",
   "language": "python",
   "name": "pycharm-ad0ef9b5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}