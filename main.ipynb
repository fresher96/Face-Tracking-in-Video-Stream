{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configurations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "'http://192.168.0.103:8080/shot.jpg'"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config_file;\n",
    "configs = config_file.readConfigs();\n",
    "configs['camera_url']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import cv2;\n",
    "import math;\n",
    "from tqdm.notebook import tqdm;\n",
    "from time import sleep;\n",
    "import termcolor;\n",
    "from ipdb import set_trace;\n",
    "import PIL;\n",
    "import IPython;\n",
    "from io import BytesIO;\n",
    "\n",
    "class DatabaseLogger():\n",
    "\n",
    "    def log(self, people):\n",
    "        data = pd.DataFrame(columns=['']);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VideoStreamBase():\n",
    "\n",
    "    def __del__(self):\n",
    "        cv2.VideoCapture(0).release();\n",
    "        cv2.destroyAllWindows();\n",
    "\n",
    "    def getImage(self) -> np.ndarray:\n",
    "        raise NotImplementedError();\n",
    "\n",
    "    def displayVideo(self, limit: int = 0, lag: int = 0, display_id: int = 1, width: int = 400, height: int = 200):\n",
    "        try:\n",
    "            while(self.displayImage(display_id, width, height)):\n",
    "                sleep(lag);\n",
    "        except(KeyboardInterrupt):\n",
    "            print(termcolor.colored('video stream stopped voluntarily', 'green'));\n",
    "\n",
    "    def displayImage(self, display_id: int = None, width: int = 400, height: int = 200, img = None) -> bool:\n",
    "        img = self.getImage() if img is None else img;\n",
    "        if(img is None): return False;\n",
    "\n",
    "        img = PIL.Image.fromarray(img, 'RGB')\n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, format=\"jpeg\")\n",
    "        display(\n",
    "            IPython.display.Image(\n",
    "                data=buffer.getvalue(), format='jpeg', width=width, height=height\n",
    "                ), display_id=display_id);\n",
    "\n",
    "        return True;\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError();\n",
    "\n",
    "    def fps(self):\n",
    "        raise NotImplementedError();\n",
    "\n",
    "    def download(self, path: str = './output.mp4', fps: float = None, limit: int = None, display: bool = False,\n",
    "                 safeMode: bool = True, width: int = None, height: int = None):\n",
    "\n",
    "        nFrame = 1 if len(self) == 1 else (len(self) - 1 if limit is None else limit);\n",
    "        if(nFrame == 0): raise Exception('No Frames Found');\n",
    "\n",
    "        img = self.getImage();\n",
    "\n",
    "        if(height is None): height = img.shape[0];\n",
    "        if(width  is None): width  = img.shape[1];\n",
    "\n",
    "        fourcc =  cv2.VideoWriter_fourcc(*'XVID');\n",
    "        fps_ = self.fps() if fps is None else fps;\n",
    "        outputVideo = cv2.VideoWriter(path, fourcc, fps_, (width, height), 1)\n",
    "\n",
    "        # set_trace();\n",
    "        with tqdm(total=nFrame) as progressbar:\n",
    "            currentFrame = 0;\n",
    "            nextImg = None;\n",
    "            while(currentFrame < nFrame and img is not None):\n",
    "                try:\n",
    "                    if(display): self.displayImage(1, width, height, img);\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB);\n",
    "                    nextImg = self.getImage();\n",
    "                except Exception as e:\n",
    "                    if(safeMode):\n",
    "                        print(termcolor.colored('Exception:', 'red'));\n",
    "                        print(e);\n",
    "                    else:\n",
    "                        raise e;\n",
    "\n",
    "                outputVideo.write(img);\n",
    "                currentFrame += 1;\n",
    "                progressbar.update(1);\n",
    "                img = nextImg;\n",
    "\n",
    "        outputVideo.release();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import face_recognition;\n",
    "import os;\n",
    "import json;\n",
    "\n",
    "\n",
    "class FaceDetector(VideoStreamBase):\n",
    "\n",
    "    video: VideoStreamBase\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video);\n",
    "\n",
    "    def fps(self):\n",
    "        return self.video.fps();\n",
    "\n",
    "    def __init__(self, video: VideoStreamBase):\n",
    "        self.video = video;\n",
    "\n",
    "        self.known_faces = None;\n",
    "        with open(configs['db_face'], 'r') as f:\n",
    "            embeddings = json.load(f);\n",
    "\n",
    "            self.known_faces = [None] * len(embeddings);\n",
    "            for el in embeddings:\n",
    "                self.known_faces[el['id']] = np.array(el['embedding']);\n",
    "\n",
    "        self.known_names = None;\n",
    "        with open(configs['db_person'], 'r') as f:\n",
    "            people = json.load(f);\n",
    "\n",
    "            self.known_names = [None] * len(people);\n",
    "            assert(len(self.known_names) == len(self.known_faces))\n",
    "\n",
    "            for el in people:\n",
    "                self.known_names[el['face']] = (el['id'], el['name']);\n",
    "\n",
    "    def getImage(self):\n",
    "        img = self.video.getImage();\n",
    "        if(img is None): return None;\n",
    "\n",
    "        face_locations = face_recognition.face_locations(img, model=configs['face_locations_model'])\n",
    "        face_encodings = face_recognition.face_encodings(img, face_locations, model=configs['face_encodings_model'])\n",
    "        # set_trace();\n",
    "\n",
    "        people = [];\n",
    "        for face_encoding in face_encodings:\n",
    "\n",
    "            # print(type(face_encoding), face_encoding);\n",
    "            # print(type(self.known_faces[0]), self.known_faces[0]);\n",
    "\n",
    "            tolerance = 0.60;\n",
    "            # match = face_recognition.compare_faces(self.known_faces, face_encoding, tolerance=tolerance)\n",
    "            match = face_recognition.face_distance(self.known_faces, face_encoding)\n",
    "\n",
    "            # id = np.argmax(match);\n",
    "            # name = self.known_names[id] if match[id] else None;\n",
    "\n",
    "            id = np.argmin(match);\n",
    "            personId, name = (self.known_names[id]) if (match[id] <= tolerance) else (None, None);\n",
    "\n",
    "            people.append((personId, name));\n",
    "\n",
    "        for (top, right, bottom, left), name in zip(face_locations, people):\n",
    "            color = (255, 0, 0) if name is None else (0, 255, 0);\n",
    "            cv2.rectangle(img, (left, top), (right, bottom), color, 2);\n",
    "\n",
    "            if(name is None): continue;\n",
    "\n",
    "            cv2.rectangle(img, (left, bottom - 42), (right, bottom), color, cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(img, name, (left + 5, bottom - 8), font, 1.5, (0, 0, 0), 2);\n",
    "\n",
    "        return img;\n",
    "\n",
    "# video = FaceDetector(VideoReader(videoFile), facesDir);\n",
    "# video.download(outputFile, 25);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Classes for Local Setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import cv2;\n",
    "import termcolor;\n",
    "\n",
    "\n",
    "class LocalVideoStream(VideoStreamBase):\n",
    "\n",
    "    def displayVideo(self, fps = 30, displayName = 'Streaming'):\n",
    "        while(True):\n",
    "            img = self.getImage();\n",
    "            if(img is None): break;\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR);\n",
    "            cv2.imshow(displayName, img);\n",
    "\n",
    "            if(cv2.waitKey(1) & 0xFF == ord('q')): # press `q` to break\n",
    "                break;\n",
    "\n",
    "\n",
    "        print(termcolor.colored('video stream stopped voluntarily', 'green'));\n",
    "        print(termcolor.colored('WARNING: object deleted', 'yellow'));\n",
    "#         self.__del__();\n",
    "        super(LocalVideoStream, self).__del__();\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class LocalFaceDetector(LocalVideoStream, FaceDetector):\n",
    "    def __init__(self, video: VideoStreamBase):\n",
    "        super(LocalFaceDetector, self).__init__(video);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Offilne Setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import IPython\n",
    "import PIL\n",
    "\n",
    "\n",
    "class VideoReader(LocalVideoStream):\n",
    "\n",
    "    def __init__(self, file):\n",
    "        self.capture = cv2.VideoCapture(file)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.capture.release()\n",
    "        super(VideoReader, self).__del__();\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.capture.get(cv2.CAP_PROP_FRAME_COUNT));\n",
    "\n",
    "    def fps(self):\n",
    "        return self.capture.get(cv2.CAP_PROP_FPS);\n",
    "\n",
    "    def getImage(self):\n",
    "        ret, frame = self.capture.read()\n",
    "        if(ret == False): return None;\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return frame;\n",
    "\n",
    "# video = VideoReader(configs['video_file']);\n",
    "# video.displayVideo();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e7976ef18a344218f94f9b342936f77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video = LocalFaceDetector(VideoReader(configs['video_file']));\n",
    "video.download(configs['output_file'], limit=5);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (AIR_project)",
   "language": "python",
   "name": "pycharm-ad0ef9b5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}